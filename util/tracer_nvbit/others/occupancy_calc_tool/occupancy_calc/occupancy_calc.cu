/* Copyright (c) 2017, NVIDIA CORPORATION. All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 *  * Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 *  * Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 *  * Neither the name of NVIDIA CORPORATION nor the names of its
 *    contributors may be used to endorse or promote products derived
 *    from this software without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
 * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
 * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
 * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

/* Author: Oreste Villa, ovilla@nvidia.com - 2018 */

#include <assert.h>
#include <pthread.h>
#include <stdint.h>
#include <stdio.h>

/* every tool needs to include this once */
#include "nvbit_tool.h"

/* nvbit interface file */
#include "nvbit.h"

/* provide some __device__ functions */
#include "utils/utils.h"

/* kernel id counter, maintained in system memory */
uint32_t kernel_id = 0;

/* total instruction counter, maintained in system memory, incremented by
 * "counter" every time a kernel completes  */
uint64_t tot_app_instrs = 0;

/* kernel instruction counter, updated by the GPU */
__managed__ uint64_t counter = 0;

/* global control variables for this tool */
uint32_t instr_begin_interval = 0;
uint32_t instr_end_interval = UINT32_MAX;
uint32_t ker_begin_interval = 0;
uint32_t ker_end_interval = UINT32_MAX;
int verbose = 0;
int count_warp_level = 1;
int exclude_pred_off = 0;

/* a pthread mutex, used to prevent multiple kernels to run concurrently and
 * therefore to "corrupt" the counter variable */
pthread_mutex_t mutex;

bool skip_flag = false;
bool alternate = false;

/* nvbit_at_init() is executed as soon as the nvbit tool is loaded. We typically
 * do initializations in this call. In this case for instance we get some
 * environment variables values which we use as input arguments to the tool */
void nvbit_at_init() {
  /* just make sure all managed variables are allocated on GPU */
  setenv("CUDA_MANAGED_FORCE_DEVICE_ALLOC", "1", 1);

  /* we get some environment variables that are going to be use to selectively
   * instrument (within a interval of kernel indexes and instructions). By
   * default we instrument everything. */
  GET_VAR_INT(
      instr_begin_interval, "INSTR_BEGIN", 0,
      "Beginning of the instruction interval where to apply instrumentation");
  GET_VAR_INT(instr_end_interval, "INSTR_END", UINT32_MAX,
              "End of the instruction interval where to apply instrumentation");
  GET_VAR_INT(ker_begin_interval, "KERNEL_BEGIN", 0,
              "Beginning of the kernel launch interval where to apply "
              "instrumentation");
  GET_VAR_INT(
      ker_end_interval, "KERNEL_END", UINT32_MAX,
      "End of the kernel launch interval where to apply instrumentation");
  GET_VAR_INT(count_warp_level, "COUNT_WARP_LEVEL", 1,
              "Count warp level or thread level instructions");
  GET_VAR_INT(exclude_pred_off, "EXCLUDE_PRED_OFF", 0,
              "Exclude predicated off instruction from count");
  GET_VAR_INT(verbose, "TOOL_VERBOSE", 0, "Enable verbosity inside the tool");
  std::string pad(100, '-');
  printf("%s\n", pad.c_str());
}

/* This call-back is triggered every time a CUDA driver call is encountered.
 * Here we can look for a particular CUDA driver call by checking at the
 * call back ids  which are defined in tools_cuda_api_meta.h.
 * This call back is triggered bith at entry and at exit of each CUDA driver
 * call, is_exit=0 is entry, is_exit=1 is exit.
 * */
void nvbit_at_cuda_event(CUcontext ctx, int is_exit, nvbit_api_cuda_t cbid,
                         const char *name, void *params, CUresult *pStatus) {
  if (skip_flag)
    return;
  /* Identify all the possible CUDA launch events */
  if (cbid == API_CUDA_cuLaunch || cbid == API_CUDA_cuLaunchKernel_ptsz ||
      cbid == API_CUDA_cuLaunchGrid || cbid == API_CUDA_cuLaunchGridAsync ||
      cbid == API_CUDA_cuLaunchKernel) {
    /* cast params to cuLaunch_params since if we are here we know these are
     * the right parameters type */
    cuLaunch_params *p = (cuLaunch_params *)params;
    cuLaunchKernel_params_st *p_2 = (cuLaunchKernel_params_st *)params;

    // Print out the occupancy for each kernel
    if (alternate) {
      alternate = false;
      int blocks;
      int threads = p_2->blockDimX * p_2->blockDimY * p_2->blockDimZ;
      CUDA_SAFECALL(cuOccupancyMaxActiveBlocksPerMultiprocessor(
          &blocks, p->f, threads, p_2->sharedMemBytes));
      printf("Kernel = %s\n", nvbit_get_func_name(ctx, p->f));
      // Warning! Only for volta with 80 SMs
      printf("Max Blocks / GPU = %d\n", blocks * 80);
      skip_flag = false;
    } else {
      alternate = true;
    }
    if (!is_exit) {
      /* if we are entering in a kernel launch:
       * 1. Lock the mutex to prevent multiple kernels to run concurrently
       * (overriding the counter) in case the user application does that
       * 2. Select if we want to run the instrumented or original
       * version of the kernel
       * 3. Reset the kernel instruction counter */

      pthread_mutex_lock(&mutex);
    } else {
      /* if we are exiting a kernel launch:
       * 1. Wait until the kernel is completed using
       * cudaDeviceSynchronize()
       * 2. Get number of thread blocks in the kernel
       * 3. Print the thread instruction counters
       * 4. Release the lock*/
      CUDA_SAFECALL(cudaDeviceSynchronize());
      pthread_mutex_unlock(&mutex);
    }
  }
}
